---
layout: archive
title: "Projects"
permalink: /projects/
author_profile: true
---

{% include base_path %}

## <a href="https://uvents.nus.edu.sg/event/18th-steps">18th STePs, held on April 14, 2021</a>
_Warning_ ‚ö†Ô∏è: This webpage is still editing. ‚ö†Ô∏è

## Description

The School of Computing Term Project Showcase <a href="https://uvents.nus.edu.sg/homepage/events">(STePs)</a> is one of the largest event, similar to Trade shows, aims to bring together and present selected student projects/products in the School of Computing (SoC) to facilitate independent peer learning, entrepreneurship and effective employment with modern flipped career-fair approach. In addition, STePS facilitates better assessment model through multi-party assessment of course projects. It's a festive yet serious class showcase, in which students present their projects in all aspects of computer science and information systems to the respective Faculty, Industry guests, Government agencies, Sponsors and Investors for grading, to connect with potential employers and to seek opportunities for further development of their work through collaboration with Industry and Investors. 

In AY20/21 Sem II, CS6101 Conversational Recommendation Systems attended 18th STePs.There are 26 students in 10 teams focus on recent research on the topics of Conversational Systems, Recommender Systems and their intersections.

## <a href = "https://uvents.nus.edu.sg/event/18th-steps/module/CS6101">18th STePs: Conversational Recommendation System Project Showcase Page</a>  

## Project Showcase
Below is a listing of the projects from this past semester (2020). The winners are listed out. 
### üèÜ 1st place, Team 07: Extending Neural Collaborative Filtering<BR/>
üìñ Abstract <BR/>
Extending the Neural Collaborative Filtering Framework to improve model understanding and robustness. Using additional Convolutional layers, Pairwise Loss Function and Auxiliary Information Embedding to explore potential model improvements.<BR/>
‚úçÔ∏è Description <BR/>
In our project, we explore the potential extensions to the Neural Collaborative Filtering (NCF) Framework to improve model understanding and robustness. Using additional Convolutional layers, Pairwise Loss Function and Auxiliary Information Embedding, we experiment with the MovieLens-1M dataset to attain better model performance on Hit Rate and NDCG metrics while attempting to improve model understanding through auxiliary embeddings.<BR/>
‚òÄÔ∏è Team Member <BR/>
- Gabriel Loye, NUS SoC Undergraduate 
- Clarence Ong, NUS SoC Undergraduate [&nbsp;<a href="https://www.linkedin.com/in/clarenceong97/?originalSubdomain=sg">LinkedIn</a>&nbsp;]
- Nham Quoc Hung, NUS SoC Undergraduate [&nbsp;<a href="https://www.linkedin.com/in/quoc-hung-nham/?originalSubdomain=sg">LinkedIn</a>&nbsp;]
- Sashankh CK, External Guest 

 üìª Media Links<BR/> 
[&nbsp;<a href="https://github.com/gabrielloye/neural_collaborative_filtering">Homepage</a>&nbsp;]
[&nbsp;<a href="https://raw.githubusercontent.com/gabrielloye/neural_collaborative_filtering/master/assets/CS6101_Neural_Collaborative_Filtering_Poster.png">Poster</a>&nbsp;]
 ### ü•à 2nd place, Team 04: Causal Estimation for Conversational Recommender Systems
üìñ Abstract <BR/>
In this project, we study popularity bias in Recommender System (RecSys), Conversational Recsys, and their interplays.<BR/>
‚úçÔ∏è Description <BR/>
We discover (1) conversation can significantly mitigate popularity bias for traditional RecSys; (2) Conversation RecSys suffers from popularity bias itself. We propose a method to mitigate popularity bias in Conversational RecSys. Please refer to our poster for technical details. Our experiment is still WIP, we will update on this github repo: https://github.com/YisongMiao/cs6101 <BR/>
‚òÄÔ∏è Team Member <BR/>
- Yisong Miao, NUS Postgraduate Student  [&nbsp;<a href="https://yisong.me/">Personal Website</a>&nbsp;]
- Chenxin Wang, NUS Postgraduate Student [&nbsp;<a href="https://www.linkedin.com/in/chengxin-wang-086304113/?originalSubdomain=sg">LinkedIn</a>&nbsp;]

üìª Media Links<BR/> 
[&nbsp;<a href="https://github.com/YisongMiao/cs6101">Homepage</a>&nbsp;]
[&nbsp;<a href="https://yisong.me/publications/CausalEst-Poster.jpeg">Poster</a>&nbsp;]
### ü•â 3rd place, Team 09: Beyond IGMC
üìñ Abstract <BR/>
We extend the state-of-the-art Inductive Graph Matrix Completion recommender system by introducing Graph Normalization and Layer Aggregation variants, and explore the models' potent transfer learning capabilities<BR/>
‚úçÔ∏è Description <BR/>
In this project, we investigate how recent advances in Graph Neural Network models can impact and even improve the ability of the state-of-the-art Inductive Graph Matrix Completion (IGMC) recommender system to predict ratings in the setting of only having ratings of each user-item interaction. We show this through measuring the baseline model performance against the extensions using the RMSE scoring. 

The IGMC is able to perform inductive matrix completion without any reliance on side-information. This allows the model to be highly applicable in many recommender system settings. It is also able to successfully transfer learning to other datasets with completely different recommender tasks and user bases.
We contribute 2 main extensions to the model, in particular: Graph-Normalisation and Layer Aggregation alternatives. We also extended the model visualisation and conducted meso-analysis on training examples with the greatest contributions to RMSE values. Furthermore, we explore the transfer learning capabilities of these inductive models, and benchmark the results against external datasets.<BR/>
‚òÄÔ∏è Team Member <BR/>
- Stephen Tan, NUS SoC Undergraduate [&nbsp;<a href="https://www.linkedin.com/in/stephen-tan-hin-khai/?originalSubdomain=sg">LinkedIn</a>&nbsp;]
- Axel Lau Wei En, NUS SoC Undergraduate [&nbsp;<a href="https://www.linkedin.com/in/axel-lau/?originalSubdomain=sg">LinkedIn</a>&nbsp;]
- Joel Tan Wan Rong, NUS SoC Undergraduate [&nbsp;<a href="https://www.linkedin.com/in/joeltanwr/?originalSubdomain=sg">LinkedIn</a>&nbsp;]
- Wendi Ren, External Guest
- Chan Guan Hao, External Guest 

üìª Media Links<BR/> 
[&nbsp;<a href="https://linktr.ee/BeyondIGMC">Homepage</a>&nbsp;]
[&nbsp;<a href="https://www.youtube.com/watch?v=pEQxq7r-lgY">Video</a>&nbsp;]
[&nbsp;<a href="https://drive.google.com/file/d/1Hso_rqGMXnJsRt1V9QmLUUGgbO6OcvZI/view">Poster</a>&nbsp;]
### Team 01: Explore Multiple Response Modalities of DialogWAE
üìñ Abstract <BR/>
This project is focusing on assessing and interpreting the GMM prior components in DialogWAE<BR/>
‚úçÔ∏è Description <BR/>
Neural response generation is a typical task in NLP community. DialogWAE is a new approach for dialogue modeling and response generation, which achieves SOTA result on popular datasets. In this work, we focus on exploring the various modalities of the generated responses. To be specific, we propose to: 
‚Ä¢	Analyze how the number K of prior components influences the overall performance 
‚Ä¢	Explore what each prior component of the Gaussian mixture distribution captures when K > 3<BR/>
‚òÄÔ∏è Team Member <BR/>
- Liu Ruofan, NUS Postgraduate Student [&nbsp;<a href="https://www.linkedin.com/in/ruofanliu/?originalSubdomain=sg">LinkedIn</a>&nbsp;]
- Liu Hongfu, NUS Postgraduate Student 
- Liu Yong, NUS Postgraduate Student [&nbsp;<a href="https://www.linkedin.com/in/yong-liu-b1037513/?originalSubdomain=sg">LinkedIn</a>&nbsp;]
 
üìª Media Links<BR/> 
[&nbsp;<a href=" https://github.com/lindsey98/DialogWAE">Homepage</a>&nbsp;]
[&nbsp;<a href="https://postimg.cc/sQN3hscm">Poster</a>&nbsp;]

 
 




